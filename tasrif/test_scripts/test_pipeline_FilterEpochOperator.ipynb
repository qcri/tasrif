{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "amber-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'Hours': pd.date_range('2018-01-01', '2018-01-10', freq='1H', closed='left'),\n",
    "        'Steps': np.random.randint(100,10000, size=9*24),\n",
    "        }\n",
    "     )\n",
    "\n",
    "ids = []\n",
    "for i in range(1, 217):\n",
    "    ids.append(i%10 + 1)\n",
    "    \n",
    "df[\"Id\"] = ids\n",
    "\n",
    "\n",
    "# Add day for id 1\n",
    "df = df.append({'Hours': datetime.datetime(2020, 2, 2), 'Steps': 2000, 'Id': 1}, ignore_index=True)\n",
    "\n",
    "# Remove 5 days from id 10\n",
    "id_10_indices = df.loc[df.Id == 10].index.values[:-5]\n",
    "df = df[~df.index.isin(id_10_indices)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "solar-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterOperator:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        participant_id_column=\"id\",\n",
    "        ts_column=\"time\",\n",
    "        epoch_filter=\"\",\n",
    "        day_filter=None,\n",
    "        filter_type=\"include\"):\n",
    "        \n",
    "        self.participant_id_column = participant_id_column\n",
    "        self.ts_column = ts_column\n",
    "        self.epoch_filter = epoch_filter\n",
    "        self.day_filter = day_filter\n",
    "        self.filter_type= filter_type    \n",
    "   \n",
    "    def process(self, *data_frames):\n",
    "        \n",
    "        processed = []\n",
    "        \n",
    "        for data_frame in data_frames:\n",
    "            processed_df = None\n",
    "   \n",
    "            if type(self.epoch_filter) == str:\n",
    "                if self.filter_type == \"include\":\n",
    "                    processed_df = data_frame.query(self.epoch_filter)\n",
    "                else:\n",
    "                    processed_df = data_frame.query(f\"not ({self.epoch_filter})\")\n",
    "            else:\n",
    "                if self.filter_type == \"include\":       \n",
    "                    processed_df = data_frame[self.epoch_filter(data_frame)]                     \n",
    "                else:\n",
    "                    processed_df = data_frame[~self.epoch_filter(data_frame)]\n",
    "\n",
    "            if self.day_filter:\n",
    "\n",
    "                if type(self.day_filter) == dict:            \n",
    "                    index = processed_df.groupby([\n",
    "                        self.participant_id_column, \n",
    "                        processed_df[self.ts_column].dt.date])[self.day_filter['column']].transform(\n",
    "                            self.day_filter['filter'])\n",
    "                    \n",
    "                    if filter_type == \"include\":\n",
    "                        processed_df = processed_df.loc[index]\n",
    "                    else:\n",
    "                        processed_df = processed_df.loc[~index]\n",
    "                        \n",
    "                    if ('consecutive_days' in self.day_filter) and not processed_df.empty:\n",
    "                        processed_df = self.consecutive_days_filter(processed_df, self.day_filter['consecutive_days'])\n",
    "\n",
    "\n",
    "                elif type(self.day_filter == list):\n",
    "                    for day_filter_item in self.day_filter:\n",
    "                        index = processed_df.groupby([\n",
    "                            self.participant_id_column, \n",
    "                            processed_df[self.ts_column].dt.date])[day_filter_item['column']].transform(\n",
    "                                day_filter_item['filter'])\n",
    "                \n",
    "                        if self.filter_type == \"include\":\n",
    "                            processed_df = processed_df.loc[index]\n",
    "                        else:\n",
    "                            processed_df = processed_df.loc[~index]\n",
    "                \n",
    "                        if ('consecutive_days' in day_filter_item) and not processed_df.empty:\n",
    "                            processed_df = self.consecutive_days_filter(processed_df, day_filter_item['consecutive_days'])\n",
    "\n",
    "            processed.append(processed_df)\n",
    "            \n",
    "        return processed\n",
    "    \n",
    "    def consecutive_days_filter(df, min_consecutive_days):\n",
    "        days_per_id = df.groupby([self.participant_id_column, pd.Grouper(key=self.ts_column, freq='D')]).sum().reset_index()\n",
    "        \n",
    "        # Take the date difference between a row and its previous row\n",
    "        # If the difference is not 1 day, we start a new label for the sequence using pd.cumsum()\n",
    "        label_of_consecutive_days_per_id = days_per_id.groupby(self.participant_id_column)[self.ts_column].diff().dt.days.ne(1).cumsum()\n",
    "        consecutive_days_per_id = days_per_id.groupby([self.participant_id_column, self.label_of_consecutive_days_per_id]).size().reset_index(level=1, drop=True)\n",
    "\n",
    "        # Match the index with the sequence labels\n",
    "        consecutive_days_per_id = consecutive_days_per_id.reset_index()\n",
    "        consecutive_days_per_id.index = consecutive_days_per_id.index + 1\n",
    "\n",
    "        # Find the sequence label that matches the criteria\n",
    "        sequences_to_keep = consecutive_days_per_id[consecutive_days_per_id[0] > min_consecutive_days].index.values\n",
    "\n",
    "        # Find days to keep: Given the day sequence labels, include the one's in sequences_to_keep\n",
    "        days_to_keep = days_per_id[label_of_consecutive_days_per_id.isin(sequences_to_keep)]\n",
    "\n",
    "        df = df.groupby(self.participant_id_column).apply(lambda x: self.keep_days_in_df(x, days_to_keep)).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def keep_days_in_df(df, days_to_keep):\n",
    "        # Helper function for consecutive_days_filter\n",
    "        days = days_to_keep.loc[days_to_keep[self.participant_id_column] == df.name, self.ts_column].dt.date\n",
    "        return df[df[self.ts_column].dt.date.isin(days)]\n",
    "\n",
    "        \n",
    "\n",
    "def filter_operator(\n",
    "    data_frame,    \n",
    "    participant_id_column=\"id\",\n",
    "    ts_column=\"time\",\n",
    "    epoch_filter=\"\",\n",
    "    day_filter=None,\n",
    "    filter_type=\"include\"):\n",
    "    \n",
    "    processed_df = None\n",
    "   \n",
    "    if type(epoch_filter) == str:\n",
    "        if filter_type == \"include\":\n",
    "            processed_df = data_frame.query(epoch_filter)\n",
    "        else:\n",
    "            processed_df = data_frame.query(f\"not ({epoch_filter})\")\n",
    "    else:\n",
    "        if filter_type == \"include\":       \n",
    "            processed_df = data_frame[epoch_filter(df)] \n",
    "        else:\n",
    "            processed_df = data_frame[~epoch_filter(df)]\n",
    "\n",
    "    if day_filter:\n",
    "        \n",
    "        if type(day_filter) == dict:            \n",
    "            index = processed_df.groupby([\n",
    "                participant_id_column, \n",
    "                processed_df[ts_column].dt.date])[day_filter['column']].transform(\n",
    "                    day_filter['filter'])\n",
    "            if filter_type == \"include\":\n",
    "                processed_df = processed_df.loc[index]\n",
    "            else:\n",
    "                processed_df = processed_df.loc[~index]\n",
    "            \n",
    "            print(processed_df)\n",
    "            if ('consecutive_days' in day_filter) and not processed_df.empty:\n",
    "                processed_df = consecutive_days_filter(processed_df, day_filter['consecutive_days'])\n",
    "                \n",
    "        elif type(day_filter == list):\n",
    "            for day_filter_item in day_filter:\n",
    "                index = processed_df.groupby([\n",
    "                    participant_id_column, \n",
    "                    processed_df[ts_column].dt.date])[day_filter_item['column']].transform(\n",
    "                        day_filter_item['filter'])\n",
    "                if filter_type == \"include\":\n",
    "                    processed_df = processed_df.loc[index]\n",
    "                else:\n",
    "                    processed_df = processed_df.loc[~index]\n",
    "                \n",
    "                if ('consecutive_days' in day_filter_item) and not processed_df.empty:\n",
    "                    processed_df = consecutive_days_filter(processed_df, day_filter_item['consecutive_days'])\n",
    "            \n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def consecutive_days_filter(df, min_consecutive_days):\n",
    "    days_per_id = df.groupby(['Id', pd.Grouper(key='Hours', freq='D')]).sum().reset_index()\n",
    "    \n",
    "    \n",
    "    # Take the date difference between a row and its previous row\n",
    "    # If the difference is not 1 day, we start a new label for the sequence using pd.cumsum()\n",
    "    label_of_consecutive_days_per_id = days_per_id.groupby('Id')['Hours'].diff().dt.days.ne(1).cumsum()\n",
    "    consecutive_days_per_id = days_per_id.groupby(['Id', label_of_consecutive_days_per_id]).size().reset_index(level=1, drop=True)\n",
    "    \n",
    "    # Match the index with the sequence labels\n",
    "    consecutive_days_per_id = consecutive_days_per_id.reset_index()\n",
    "    consecutive_days_per_id.index = consecutive_days_per_id.index + 1\n",
    "    \n",
    "    # Find the sequence label that matches the criteria\n",
    "    sequences_to_keep = consecutive_days_per_id[consecutive_days_per_id[0] > min_consecutive_days].index.values\n",
    "\n",
    "    # Find days to keep: Given the day sequence labels, include the one's in sequences_to_keep\n",
    "    days_to_keep = days_per_id[label_of_consecutive_days_per_id.isin(sequences_to_keep)]\n",
    "    \n",
    "\n",
    "\n",
    "    df = df.groupby('Id').apply(lambda x: keep_days_in_df(x, days_to_keep)).reset_index(drop=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def keep_days_in_df(df, days_to_keep):\n",
    "    # Helper function for consecutive_days_filter\n",
    "    days = days_to_keep.loc[days_to_keep['Id'] == df.name, 'Hours'].dt.date\n",
    "    return df[df['Hours'].dt.date.isin(days)]\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "final-marks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                  Hours  Steps  Id\n",
       " 0   2018-01-01 00:00:00   9867   2\n",
       " 1   2018-01-01 01:00:00   2856   3\n",
       " 2   2018-01-01 02:00:00   7532   4\n",
       " 4   2018-01-01 04:00:00   3190   6\n",
       " 5   2018-01-01 05:00:00   5468   7\n",
       " ..                  ...    ...  ..\n",
       " 212 2018-01-09 20:00:00   3593   4\n",
       " 213 2018-01-09 21:00:00   7631   5\n",
       " 214 2018-01-09 22:00:00   6720   6\n",
       " 215 2018-01-09 23:00:00   6301   7\n",
       " 216 2020-02-02 00:00:00   2000   1\n",
       " \n",
       " [151 rows x 3 columns]]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operator = FilterOperator(epoch_filter=lambda df: df['Steps'] < 2000, filter_type=\"exclude\")\n",
    "operator.process(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "incident-moses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Hours  Steps  Id\n",
      "0   2018-01-01 00:00:00   9867   2\n",
      "1   2018-01-01 01:00:00   2856   3\n",
      "2   2018-01-01 02:00:00   7532   4\n",
      "3   2018-01-01 03:00:00    626   5\n",
      "4   2018-01-01 04:00:00   3190   6\n",
      "..                  ...    ...  ..\n",
      "212 2018-01-09 20:00:00   3593   4\n",
      "213 2018-01-09 21:00:00   7631   5\n",
      "214 2018-01-09 22:00:00   6720   6\n",
      "215 2018-01-09 23:00:00   6301   7\n",
      "216 2020-02-02 00:00:00   2000   1\n",
      "\n",
      "[201 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df3 = filter_operator(\n",
    "    df, \n",
    "    participant_id_column=\"Id\",\n",
    "    ts_column=\"Hours\",\n",
    "    epoch_filter=lambda df: df['Steps'] > 10, \n",
    "    day_filter={\n",
    "        \"column\": \"Hours\",\n",
    "        \"filter\": lambda x: x.count() < 10,\n",
    "        \"consecutive_days\": 5\n",
    "    },\n",
    "    filter_type=\"include\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "afraid-warehouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2018-01-08 00:00:00</td>\n",
       "      <td>8678</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2018-01-08 10:00:00</td>\n",
       "      <td>3764</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2018-01-08 20:00:00</td>\n",
       "      <td>7380</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2018-01-09 06:00:00</td>\n",
       "      <td>943</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2018-01-09 16:00:00</td>\n",
       "      <td>1747</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Hours  Steps  Id\n",
       "168 2018-01-08 00:00:00   8678  10\n",
       "178 2018-01-08 10:00:00   3764  10\n",
       "188 2018-01-08 20:00:00   7380  10\n",
       "198 2018-01-09 06:00:00    943  10\n",
       "208 2018-01-09 16:00:00   1747  10"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Id == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "expired-officer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 09:00:00</td>\n",
       "      <td>4149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 19:00:00</td>\n",
       "      <td>8483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02 05:00:00</td>\n",
       "      <td>7468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02 15:00:00</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-03 01:00:00</td>\n",
       "      <td>2089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2018-01-07 23:00:00</td>\n",
       "      <td>8322</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2018-01-08 09:00:00</td>\n",
       "      <td>4355</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2018-01-08 19:00:00</td>\n",
       "      <td>7090</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2018-01-09 05:00:00</td>\n",
       "      <td>3130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2018-01-09 15:00:00</td>\n",
       "      <td>5447</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Hours  Steps  Id\n",
       "0   2018-01-01 09:00:00   4149   1\n",
       "1   2018-01-01 19:00:00   8483   1\n",
       "2   2018-01-02 05:00:00   7468   1\n",
       "3   2018-01-02 15:00:00    126   1\n",
       "4   2018-01-03 01:00:00   2089   1\n",
       "..                  ...    ...  ..\n",
       "190 2018-01-07 23:00:00   8322   9\n",
       "191 2018-01-08 09:00:00   4355   9\n",
       "192 2018-01-08 19:00:00   7090   9\n",
       "193 2018-01-09 05:00:00   3130   9\n",
       "194 2018-01-09 15:00:00   5447   9\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-billy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-marshall",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
